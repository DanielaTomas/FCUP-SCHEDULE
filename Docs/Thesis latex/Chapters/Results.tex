\chapter{Results}

\label{Results}

This chapter presents the main outcomes of the proposed \ac{mcts}-based system for \ac{cb-ctt}. The following sections explore aspects such as computational performance, feasibility of generated timetables, analysis of the exploration constant \(C\), the impact of pruning, effectiveness of the diving strategy, and a comparison against benchmark competition results.

\section{Python vs PyPy Performance}

During the development and testing of the system, both standard Python and PyPy\footnote{A Just-In-Time (JIT) compiling alternative. Link: \url{https://pypy.org/}} were evaluated for performance. While both correctly executed the \ac{mcts} algorithm, the performance difference was substantial. PyPy called over three times more functions compared to Python.

Given the compute-intensive nature of \ac{mcts}, PyPy was ultimately chosen for running all the experiments and benchmarks.

\section{Feasibility}

One of the fundamental requirements of \ac{cb-ctt} is the ability to produce feasible schedules, i.e., timetables that strictly adhere to hard constraints such as avoiding room clashes, overlapping events, and unavailable periods.

Throughout all experiments, the proposed system consistently produced feasible solutions across all tested datasets from the \ac{itc-2007} benchmark. This demonstrates the robustness of the system's constraint handling mechanisms, regardless of instance size or structural complexity, confirming the general applicability of the approach.

\section{\(C\) Parameter Behaviour}

The exploration constant \(C\) in the \ac{uct} formula (Formula \ref{uct_formula}) was varied across several orders of magnitude (from 0.1 to 1000), including the modified variant incorporating accumulated rewards (Formula \ref{modified_uct}). 

Surprisingly, the results showed that varying \(C\) had minimal impact on solution quality, which indicates a lower-than-expected sensitivity to node selection.

\section{Pruning}

The application of pruning during \ac{mcts} plays a crucial role in the efficiency of the search process.

Figure \ref{fig:without_pruning_result} illustrates the behavior of the system without pruning. The search frequently explores infeasible branches of the tree, which is evident from the large number of iterations with hard constraint violations. Although some feasible solutions are eventually discovered, the overall search efficiency is compromised due to the continuous evaluation of solutions that will be ultimately discarded.

Conversely, when pruning is applied (Figure \ref{fig:pruning_result}), the search is restricted to branches that satisfy hard constraints. As a result, the hard constraint value remains consistently at zero throughout the iterations, reflecting that pruning effectively excludes infeasible regions from the search space. This restriction allows \ac{mcts} to focus on high-quality and valid solutions, preventing wasteful exploration. The cleaner progression and stable constraint satisfaction not only accelerate convergence but also improve the overall robustness of the approach. 

While not depicted in Figure \ref{fig:pruning_result}, it is worth noting that simulations may still experience occasional hard constraint violations because pruning is applied to branches within the tree rather than across the entire search space.

\begin{figure}
 \centering
     \includegraphics[width=0.6\columnwidth]{Results/without_pruning.png}
     \includegraphics[width=0.2\columnwidth]{Results/hard_caption.png}
     \caption{Hard constraint progress without pruning during 10 minutes on the \(comp01\) instance from \ac{itc-2007}.}
     \label{fig:without_pruning_result}
\end{figure}

\begin{figure}
 \centering
    \includegraphics[width=0.6\columnwidth]{Results/pruning.png}
    \includegraphics[width=0.2\columnwidth]{Results/hard_caption.png}
    \caption{Hard constraint progress with pruning during 10 minutes on the \(comp01\) instance from \ac{itc-2007}.}
    \label{fig:pruning_result}
\end{figure}

\section{Diving}

To improve the convergence speed and solution quality during timetable generation, the \ac{mcts} algorithm incorporates a diving strategy (chapter \ref{Development} section \ref{sec:diving}). Moreover, the diving strategy complements pruning by directing attention to already feasible branches. This helps concentrate computational resources on areas of the search space that are both valid and potentially optimal.

Figure \ref{fig:diving_result} (TODO MUDAR IMAGEM!!!) illustrates the soft constraint penalty progression over time on the \texttt{comp01} instance from the \ac{itc-2007} benchmark when using the diving strategy.

The results demonstrate that the diving mechanism contributes positively to the search effectiveness:

\begin{itemize}
\item \textbf{Faster convergence:} The algorithm reaches lower penalty regions more rapidly compared to a standard breadth-oriented \ac{mcts} approach. By tracking and expanding the most promising nodes first, the diving queue helps avoid wasting iterations on less promising parts of the tree.

\item \textbf{Improved solution quality:} As observed in the soft penalty trend, the use of diving leads to an improvement compared to the approach without diving (Figure \ref{without_diving_result)). This improvement is only noticeable when we extend the run time. This shows that the diving strategy not only accelerates convergence but also contributes to reaching higher-quality solutions.

\item \textbf{Focused exploitation:} The queue-based selection mechanism ensures that the algorithm deepens the most promising paths. In practice, this limits unnecessary expansion of under-performing nodes and encourages building upon solutions with known potential.
\end{itemize}

\begin{figure}
 \centering
    \includegraphics[width=0.8\columnwidth]{Results/without_diving_result.png}
    \includegraphics[width=0.19\columnwidth]{Results/soft_caption.png}
    \caption{Soft constraint progress using the diving approach on the \(comp01\) instance from \ac{itc-2007} for 1 hour.}
    \label{fig:without_diving_result}
\end{figure}


\begin{figure}
 \centering
    \includegraphics[width=0.8\columnwidth]{Results/diving_result.png}
    \includegraphics[width=0.19\columnwidth]{Results/soft_caption.png}
    \caption{Soft constraint progress using the diving approach on the \(comp01\) instance from \ac{itc-2007} for 1 hour.}
    \label{fig:diving_result}
\end{figure}

However, in both approaches (with and without diving) it is noticeable that the algorithm eventually stagnates, reaching a point where no further improvement is observed. After an initial phase of rapid improvement, the soft penalty score often plateaus.

\section{Competition Results Comparison}

The effectiveness of the \ac{mcts}-\ac{hc} hybrid was evaluated on the official \ac{itc-2007} track 3 benchmark set. Table \ref{tab:comparison_results} presents a comparison between the best-known results submitted by Müller (competition winner) and our system for instances \(comp01.ctt\) to \(comp05.ctt\), and \(comp11.ctt\).

\begin{table}[h!]
\centering
\footnotesize
\begin{tabular}{ccccccccccccccccc}
\hline
& \multicolumn{3}{c}{\textbf{comp01}} & \multicolumn{3}{c}{\textbf{comp02}} & \multicolumn{3}{c}{\textbf{comp03}} & \multicolumn{3}{c}{\textbf{comp04}} & \multicolumn{3}{c}{\textbf{comp05}} \\
& avg & max & min & avg & max & min & avg & max & min & avg & max & min & avg & max & min \\
\textbf{Müller} & \textbf{5} & 5 & \textbf{5} & 61,3 & 70 & 51 & 94,8 & 103 & 84 & 42,8 & 48 & 37 & 343,5 & 379 & 330 \\
\textbf{Our Results} & & & & & & & & & & & & & & & \\
\end{tabular}

%\centering
%\footnotesize
%\begin{tabular}{ccccccccccccccccc}
%\hline
%& \multicolumn{3}{c}{\textbf{comp06}} & \multicolumn{3}{c}{\textbf{comp07}} & \multicolumn{3}{c}{\textbf{comp08}} & \multicolumn{3}{c}{\textbf{comp09}} & \multicolumn{3}{c}{\textbf{comp10}} \\
%& avg & max & min & avg & max & min & avg & max & min & avg & max & min & avg & max & min \\
%\textbf{Muller} & \textbf{56,8} & 65 & \textbf{48} & \textbf{33,9} & 45 & \textbf{20} & 46,5 & 55 & 41 & \textbf{113,1} & 117 & 109 & \textbf{21,3} & 27 & \textbf{16} \\
%\textbf{Our Results} & & & & & & & & & & & & & & & \\
%\end{tabular}
%
%\centering
%\footnotesize
%\begin{tabular}{ccccccccccccccccc}
%\hline
%& \multicolumn{3}{c}{\textbf{comp11}} & \multicolumn{3}{c}{\textbf{comp12}} & \multicolumn{3}{c}{\textbf{comp13}} & \multicolumn{3}{c}{\textbf{comp14}} & \multicolumn{3}{c}{\textbf{comp15}} \\
%& avg & max & min & avg & max & min & avg & max & min & avg & max & min & avg & max & min \\
%\textbf{Muller} & \textbf{0} & 0 & \textbf{0} & \textbf{351,6} & 367 & \textbf{333} & \textbf{73,9} & 81 & \textbf{66} & \textbf{61,8} & 69 & 59 & 94,8 & 103 & 84 \\
%\textbf{Our Results} & & & & & & & & & & & & & & & \\
%\end{tabular}
%
%\centering
%\footnotesize
%\begin{tabular}{ccccccccccccccccc}
%\hline
%& \multicolumn{3}{c}{\textbf{comp16}} & \multicolumn{3}{c}{\textbf{comp17}} & \multicolumn{3}{c}{\textbf{comp18}} & \multicolumn{3}{c}{\textbf{comp19}} & \multicolumn{3}{c}{\textbf{comp20}} \\
%& avg & max & min & avg & max & min & avg & max & min & avg & max & min & avg & max & min \\
%\textbf{Muller} & \textbf{41,2} & 49 & \textbf{34} & \textbf{86,6} & 92 & \textbf{83} & 91,7 & 102 & 83 & \textbf{68,8} & 74 & \textbf{62} & \textbf{34,3} & 44 & \textbf{27}  \\
%\textbf{Our Results} & & & & & & & & & & & & & & & \\
%\end{tabular}
%
%\centering
%\footnotesize
%\begin{tabular}{ccccccccccccccccc}
%\hline
%& \multicolumn{3}{c}{\textbf{comp21}} & \multicolumn{3}{c}{} &  \multicolumn{3}{c}{} & \multicolumn{3}{c}{} & \multicolumn{3}{c}{} \\
%& avg & max & min &  &  &  &  &  &  &  &  &  &  &  &  \\
%\textbf{Muller} & \textbf{108} & 121 & \textbf{103}  \\
%\textbf{Our Results} & & &  \\
%\hline
%\end{tabular}
\caption{\(comp01\)-\(comp5\) and \(comp11\) comparison}
\label{tab:comparison_results}
\end{table}

Although our approach does not yet outperform state-of-the-art methods in terms of soft constraint minimization even with an extended time, it consistently finds feasible solutions within reasonable time limits. This confirms its robustness and potential as a foundation for further refinement.

\section{Summary}

This chapter evaluated the \ac{mcts}-\ac{hc} hybrid approach across several dimensions: implementation performance, feasibility, parameter tuning, pruning impact, and solution quality. Key findings include:

\begin{itemize}
\item \textbf{Feasibility:} The system consistently generated feasible timetables in the challenging \ac{itc-2007} set of benchmark instances.

\item \textbf{Performance:} PyPy significantly outperformed standard Python, justifying its use in all experiments.

\item \textbf{Pruning:} Efficiently eliminated infeasible branches, improving search focus and convergence.

\item \textbf{Diving:} Hill Climbing successfully reduced soft constraint penalties after \ac{mcts} found a feasible solution.

\item \textbf{Competition Benchmarking:} Although solution quality was below the best-known results, the approach shows solid potential with room for optimization.
\end{itemize}